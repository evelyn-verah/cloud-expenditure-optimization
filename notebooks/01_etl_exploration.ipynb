{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb253289",
   "metadata": {},
   "source": [
    "# Cloud Expenditure Optimization – Notebook Suite\n",
    "This set of notebooks follows the architecture: ETL → Database → ML (Failure, Cost) → Dashboards.\n",
    "\n",
    "**Data input**: `../data/sample_reports_100.csv` (or `../data/sample_reports.csv`)\n",
    "\n",
    "**Outputs**: cleaned data and artifacts in `../results/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c321d176",
   "metadata": {},
   "source": [
    "## 01 – ETL & Exploration\n",
    "Load synthetic reports, clean/transform, and save `cleaned_reports.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f7859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Locate data (tries multiple paths to be repo-friendly)\n",
    "possible_paths = [\n",
    "    '../data/sample_reports_100.csv',\n",
    "    '../data/sample_reports.csv',\n",
    "    '/mnt/data/sample_reports_100.csv',\n",
    "    '/mnt/data/sample_reports.csv'\n",
    "]\n",
    "data_path = next((p for p in possible_paths if Path(p).exists()), None)\n",
    "assert data_path is not None, f'Could not find CSV. Checked: {possible_paths}'\n",
    "print('Using data file:', data_path)\n",
    "\n",
    "df = pd.read_csv(data_path, parse_dates=['timestamp'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c2240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic profiling\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2a5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize columns and basic cleaning\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# Ensure numeric\n",
    "num_cols = ['response_time_ms', 'cpu_usage', 'memory_usage', 'cost_usd']\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Fill missing numeric with median; categorical with mode\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "for c in ['system_name', 'error_code', 'status']:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].fillna(df[c].mode()[0])\n",
    "\n",
    "df.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple feature engineering examples\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day'] = df['timestamp'].dt.date.astype(str)\n",
    "df['is_peak'] = (df['hour'].between(9, 18)).astype(int)\n",
    "\n",
    "# Save cleaned dataset next to data folder or into /mnt/data\n",
    "out_candidates = ['../data/cleaned_reports.csv', '/mnt/data/cleaned_reports.csv']\n",
    "out_path = next((p for p in out_candidates if Path(p).parent.exists()), out_candidates[0])\n",
    "df.to_csv(out_path, index=False)\n",
    "print('Saved cleaned dataset to:', out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaea82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visual sanity checks (no seaborn, single-plot rule)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_daily = df.groupby('day', as_index=False)['cost_usd'].sum()\n",
    "plt.figure()\n",
    "plt.plot(df_daily['day'], df_daily['cost_usd'])\n",
    "plt.title('Daily Cloud Cost (Synthetic)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
